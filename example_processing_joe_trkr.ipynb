{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Data Processing Example - TRKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import experimentdataanalysis.analysis.dataframe_plotting as dfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import jtplot submodule from jupyterthemes IF installed\n",
    "import importlib\n",
    "jtplot_found = importlib.util.find_spec(\"jupyterthemes.jtplot\") is not None\n",
    "if jtplot_found:\n",
    "    from jupyterthemes import jtplot\n",
    "    # - currently installed theme will be used to\n",
    "    jtplot.style(ticks=False, grid=False, fscale=1.6)\n",
    "    # set the default figure size\n",
    "    jtplot.figsize(x=6., y=6.)\n",
    "    # needed to avoid spurious error messages with imshow...\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filepath parsing:\n",
    "import experimentdataanalysis.data_io.metadataparsing as metadataparsing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# REQUIRED: directory containing 2D scans\n",
    "parent_dir = ('C:\\\\Data\\\\FitTrialData\\\\TRFR_RSA')\n",
    "\n",
    "# OPTIONAL: filepath parsing rules\n",
    "this_element_keyword_list = [(\"TRKR\", \"IsTRKR?\", True),\n",
    "                             (\"RSA\", \"IsRSA?\", True)]\n",
    "next_element_keyword_list = [(\"Ind\", \"Scan_2D_Index\"),\n",
    "                             (\"2Dscan\", [\"Scan_2D_Type\", \"Scan_1D_Type\"])]\n",
    "in_this_element_keyword_list = [(\"Vcm\", \"Electric Field (V/cm)\"),\n",
    "                                (\"mT\", \"Magnetic Field (mT)\"),\n",
    "                                (\"K\", \"Set Temperature (K)\"),\n",
    "                                (\"nm\", \"Wavelength (nm)\"),\n",
    "                                (\"ps\", \"Delay Time (ps)\"),\n",
    "                                (\"run\", \"RunIndex\"),\n",
    "                                (\"V\", \"Voltage (V)\"),\n",
    "                                (\"x\", \"Scan_2D_Coord\"),\n",
    "                                (\"uWpump\", \"Pump Power (uW)\"),\n",
    "                                (\"uWprobe\", \"Probe Power (uW)\"),\n",
    "                                (\"repeats\", \"# repeats\"),\n",
    "                               ]\n",
    "parsing_keyword_lists = [this_element_keyword_list,\n",
    "                         next_element_keyword_list,\n",
    "                         in_this_element_keyword_list]\n",
    "\n",
    "# REQUIRED: data storage format information\n",
    "delimiter = '\\t'\n",
    "trailing_delimiters = False  # rows end in delimiters\n",
    "num_headerlines = 0\n",
    "column_names_row = 0\n",
    "overwriting_column_names = ['A', 'B', 'C']\n",
    "\n",
    "if not overwriting_column_names:\n",
    "    overwriting_column_names = None\n",
    "pandas_read_csv_kwargs = {\n",
    "     'skiprows': num_headerlines,\n",
    "     'header': column_names_row,\n",
    "     'names': overwriting_column_names,\n",
    "     'delimiter': delimiter,\n",
    "}\n",
    "if trailing_delimiters:  # needed to avoid problems\n",
    "    pandas_read_csv_kwargs['index_col'] = False\n",
    "\n",
    "# REQUIRED: filename key for data files, will load only these\n",
    "filename_key = '.dat'\n",
    "\n",
    "# REQUIRED: criteria for grouping runs\n",
    "# TODO: EXPAND\n",
    "run_criteria = 'directory'\n",
    "\n",
    "# OPTIONAL: info_dict-based filtering, fcns returning False if data should be ignored\n",
    "filter_fcns = [\n",
    "#                lambda info_dict: info_dict.get(\"TestPhaseShift Experiment #\") == 2,\n",
    "#                lambda info_dict: info_dict.get(\"# repeats\", 1) <= 2,\n",
    "#                lambda info_dict: \"alignment\" not in info_dict.get(\"Filepath\"),\n",
    "              ]\n",
    "\n",
    "# OPTIONAL: specify a scalar value to be used as the measurement error of given y-values, i.e., their \"error bars\"\n",
    "data_fixed_uncertainty = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_dataframes_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-37da29410130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_dataframes_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'file_dataframes_list' is not defined"
     ]
    }
   ],
   "source": [
    "file_dataframes_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pare down to just data columns what we care about \n",
    "# but add all relevant metadata as columns itself\n",
    "\n",
    "# SEMI-REQUIRED: column-generation options. may be required to prevent loss of important data\n",
    "# on a level finer than the \"run\" (e.g. filenames for individual csv's)\n",
    "info_tag_to_column_list = [('Magnetic Field (mT)', 'b_external'),\n",
    "                           ('BExternal', 'b_external'),\n",
    "                           ('Run ID', 'run_id'),\n",
    "                           ('Scan_2D_Index', 'index_2d'),\n",
    "                           ('Pump Power (uW)', 'pump_power'),\n",
    "                           ('Wavelength (nm)', 'wavelength'),\n",
    "                           ('# repeats', 'n_repeats')\n",
    "                          ]\n",
    "time_elapsed_per_delay_scan = 8.0\n",
    "time_elapsed_per_delay_pos = 1.0\n",
    "column_expression_list = ['index_2d = index_2d - 1',  # filename convention starts at 1, not at 0 like other indices\n",
    "                          'index_1d = index',\n",
    "                          'time_elapsed = ' +\n",
    "                              '@time_elapsed_per_delay_scan * index_2d + @time_elapsed_per_delay_pos * index_1d',\n",
    "                         ]\n",
    "\n",
    "# OPTIONAL: specification of specific columns in data file as x-coords, y-coords. \n",
    "#           default: X = 1st column in file, Y = 2nd column in file. \n",
    "#                    (or in terms of resulting DataFrame, X = index, Y = 1st column)\n",
    "data_xfield = None\n",
    "data_yfield = 'lockin1x'\n",
    "\n",
    "dataframes_list = []\n",
    "for file_info_dict, file_dataframe in zip(file_metadata_list, file_dataframes_list):\n",
    "    column_names = file_dataframe.columns.values.tolist()\n",
    "    if data_xfield is None:\n",
    "        data_xfield = column_names[0]\n",
    "    if data_yfield is None:\n",
    "        data_yfield = column_names[1]\n",
    "\n",
    "    # create new dataframe based on user specifications:\n",
    "    new_dataframe = pd.DataFrame(file_dataframe,\n",
    "                                 columns=[data_xfield, data_yfield, 'file_index'])\n",
    "    for info_tag, column_name in info_tag_to_column_list:\n",
    "        if info_tag in file_info_dict:\n",
    "            new_dataframe[column_name] = file_info_dict[info_tag]\n",
    "    for expression in column_expression_list:\n",
    "        new_dataframe.eval(expression, inplace=True)\n",
    "\n",
    "    # add new dataframe to list\n",
    "    dataframes_list.append(new_dataframe)\n",
    "\n",
    "full_dataframe = pd.concat(dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRKR_fit_dataframe = full_dataframe.query('scancoord > 1.0 or scancoord < -1.0')\n",
    "TRKR_fit_dataframe['n_repeats'].fillna(1.0, inplace=True)\n",
    "TRKR_fit_dataframe.rename(columns={'scancoord': 'probe_delay'}, inplace=True)\n",
    "TRKR_fit_dataframe.set_index(['run_id', 'index_2d', 'index_1d'], drop=True, append=False, inplace=True)\n",
    "TRKR_fit_dataframe.sort_index(ascending=True, inplace=True)\n",
    "df = TRKR_fit_dataframe\n",
    "TRKR_fit_dataframe.head(20)\n",
    "\n",
    "# plot newly created dataframe and show the first few rows\n",
    "plt.figure(figsize=(4,4))\n",
    "ax = plt.subplot(111)\n",
    "dfplot.plot_dataframe_2d(dataframe, 'kerr_rotation',\n",
    "                         x_values_column='probe_delay',\n",
    "                         y_values_column='b_external',\n",
    "                         ax=ax, aspect=1.0)\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas-lmfit helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from experimentdataanalysis.analysis.dataframe_processing \\\n",
    "    import df_extract_dataset_indexed_matrices, \\\n",
    "           df_extract_vector_lists_by_dataset, \\\n",
    "           df_transform_dataset_df_to_fit_row, \\\n",
    "           df_minimize_fcn_on_datasets, \\\n",
    "           df_minimize_fcn_across_linked_datasets\n",
    "\n",
    "# df_extract_dataset_indexed_matrices(df, column_names)\n",
    "# df_extract_vector_lists_by_dataset(df, column_names)\n",
    "# df_transform_dataset_df_to_fit_row(df, group_fit_params_dict,\n",
    "#                                    fit_params_to_add,\n",
    "#                                    column_aggregation_dict={},\n",
    "#                                    keep_const_columns=True)\n",
    "# df_minimize_fcn_on_datasets(df, residuals_fcn, fit_params,\n",
    "#                             independent_vars_columns,\n",
    "#                             measured_data_column,\n",
    "#                             *res_args,\n",
    "#                             column_aggregation_dict={},  # KEYWORDS ONLY!\n",
    "#                             keep_const_columns=True,\n",
    "#                             **res_kwargs)\n",
    "\n",
    "# WORK IN PROGRESS:\n",
    "# df_minimize_fcn_across_linked_datasets(df, residuals_fcn, fit_params,\n",
    "#                                        dataset_params_unpacking_fcn,\n",
    "#                                        independent_vars_columns,\n",
    "#                                        measured_data_column,\n",
    "#                                        *res_args,\n",
    "#                                        column_aggregation_dict={},  # KEYWORDS ONLY!\n",
    "#                                        keep_const_columns=True,\n",
    "#                                        **res_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset fit model and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL CONSTANTS\n",
    "GFACTORCONSTANT = 1.3996e-5  # 1/(ps*mTesla), = bohr magneton/2*pi*hbar\n",
    "LASER_REPRATE = 13158  # ps period\n",
    "\n",
    "def fitfcn_cosine(delay_time, b_external,  # <- independent vars,\n",
    "                  gfactor,  # <- potentially linked parameters across datasets in run,\n",
    "                  amplitude, phase_offset,  # <- rest are unlinked parameters unique to current dataset\n",
    "                  y_offset):\n",
    "    \"\"\"\n",
    "    Oversimplified cosine fit that assumes phase @t=0 is always 0.\n",
    "    Expected to act on very few data points, so brings in expected ang. freq using b_external.\n",
    "\n",
    "    Independent variables: delay_time (can vary), b_external (must be const.)\n",
    "    Parameters: gfactor, amplitude, phase_offset, y_offset\n",
    "\n",
    "    IMPORTANT NOTE: Despite this function taking more than one independent variable,\n",
    "    this model is ONLY 1D. Only the first should be allowed to vary during a run,\n",
    "    the other independent variables are there for convenience when fitting to pandas\n",
    "    dataframes and should really be thought of more as constant parameters (scalar\n",
    "    values are not only acceptable, they are preferred for speed reasons to the\n",
    "    alternative - arrays of same shape as first independent variable)\n",
    "    \"\"\"\n",
    "    osc_ang_freq = 2 * np.pi * GFACTORCONSTANT * gfactor * b_external\n",
    "    pos_def_delay = delay_time % LASER_REPRATE\n",
    "    signal = amplitude * np.cos(osc_ang_freq * pos_def_delay + phase_offset)\n",
    "    return signal + y_offset\n",
    "\n",
    "\n",
    "def residuals_fitfcn_cosine(params, delay_time, b_external, measured_data=None):\n",
    "    \"\"\"\n",
    "    Residual wrapper for lmfit minimize() for function fitfcn_cosine.\n",
    "    Uses given parameters and independent variables to evaluate function.\n",
    "    If data is given, returns (data - function_output) for use in least\n",
    "    squares optimization. If data is not given or None, just returns\n",
    "    the function output.\n",
    "\n",
    "    Follows the style used in the lmfit documentation on minimize().\n",
    "    \"\"\"\n",
    "    # unpack parameters:\n",
    "    #  extract .value attribute for each parameter\n",
    "    param_values = params.valuesdict()\n",
    "    gfactor      = param_values['gfactor']\n",
    "    amplitude    = param_values['amplitude']\n",
    "    phase_offset = param_values['phase_offset']\n",
    "    y_offset     = param_values['y_offset']\n",
    "    fitfcn_results = fitfcn_cosine(delay_time, b_external,\n",
    "                                   gfactor, amplitude, phase_offset, y_offset)\n",
    "    if measured_data is None:\n",
    "        return fitfcn_results\n",
    "    return fitfcn_results - measured_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset fit parameter setup and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lmfit import Parameters\n",
    "\n",
    "params_guesses = [('gfactor',        {'value' : 0.439,\n",
    "                                      'vary'  : False}),\n",
    "                  ('amplitude',      {'value' : 1e-3,\n",
    "                                      'min'   : 0.0,\n",
    "                                      'max'   : 1.0}),\n",
    "                  ('phase_offset',   {'value' : 0.0,\n",
    "                                      'min'   : -np.pi,\n",
    "                                      'max'   : +np.pi}),\n",
    "                  ('y_offset',       {'value' : 0.0,\n",
    "                                      'min'   : -1e-3,\n",
    "                                      'max'   : +1e-3}),\n",
    "                 ]\n",
    "fit_params = Parameters()\n",
    "for param_name, param_guess_dict in params_guesses:\n",
    "    fit_params.add(param_name, **param_guess_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Fit to fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.xs(0, level='run_id')\n",
    "residuals_fcn = residuals_fitfcn_cosine\n",
    "fit_params = fit_params\n",
    "independent_vars_columns = [\"probe_delay\", \"b_external\"]\n",
    "measured_data_column = \"kerr_rotation\"\n",
    "fit_params_to_add = ['amplitude', 'phase_offset']\n",
    "column_aggregation_dict = {'time_elapsed': lambda x: x.head(1).values}  # keep first time\n",
    "keep_const_columns = True\n",
    "\n",
    "dataset_results, new_df = \\\n",
    "    df_minimize_fcn_on_datasets(df, residuals_fcn, fit_params,\n",
    "                                independent_vars_columns,\n",
    "                                measured_data_column,\n",
    "                                column_aggregation_dict=column_aggregation_dict,  # keywords only!\n",
    "                                keep_const_columns=keep_const_columns)\n",
    "\n",
    "# FILTER OUT BAD FITS\n",
    "good_result_indices = []\n",
    "for dataset_index, result in enumerate(dataset_results):\n",
    "    red_flag = False\n",
    "    if result.params['phase_offset'].stderr > np.pi / 2:\n",
    "        print(\"dataset {}: \".format(dataset_index) +\n",
    "              \"phase offset error too large, ignoring dataset...\")\n",
    "        red_flag = True\n",
    "    if not red_flag:\n",
    "        good_result_indices.append(dataset_index)\n",
    "trimmed_df = new_df.iloc[good_result_indices]\n",
    "\n",
    "# GET ACTUAL RESULTS FROM SIMULATION TO COMPARE\n",
    "true_spin_lifetimes = simulation_params['spin_lifetimes'][good_result_indices]\n",
    "n500ps_decay_factors = np.exp(-(LASER_REPRATE - 500.0) / true_spin_lifetimes)\n",
    "true_amplitudes = n500ps_decay_factors * simulation_params['pulse_amplitudes'][good_result_indices]\n",
    "true_phase_offsets = simulation_params['extra_phase_offsets'][good_result_indices]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "plt.plot(trimmed_df.b_external, true_amplitudes, 'r')\n",
    "plt.errorbar(x=trimmed_df.b_external, y=trimmed_df.amplitude, yerr=trimmed_df.amplitude_error)\n",
    "# new_df['amplitude'].plot.line(ax=ax1)\n",
    "plt.title('amplitude')\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "plt.plot(trimmed_df.b_external, true_phase_offsets, 'r')\n",
    "plt.errorbar(x=trimmed_df.b_external, y=trimmed_df.phase_offset, yerr=trimmed_df.phase_offset_error)\n",
    "# new_df['phase_offset'].plot.line(ax=ax2)\n",
    "plt.title('phase_offset')\n",
    "new_df.head()\n",
    "\n",
    "# indices_to_show = [0, 1]\n",
    "# for dataset_index in indices_to_show:\n",
    "#     if dataset_index not in good_result_indices:\n",
    "#         print(\"Error: index {} does not exist \".format(dataset_index) +\n",
    "#               \"or fit was unsuccessful\")\n",
    "#     else:\n",
    "#         dataset_df = df.loc[]\n",
    "#         fit_result = dataset_results[dataset_index]\n",
    "#         try:\n",
    "#             fit_result.plot()  # REQUIRES A MODEL FIT, NOT MINIMIZER FIT!\n",
    "#         except AttributeError:  # note: assumes standard lmfit fitfcn form\n",
    "#             raise NotImplementedError()\n",
    "#             x_vectors = [df.\n",
    "#                          for colname in independent_vars_columns]\n",
    "#             fit_yvals = residuals_fcn(fit_result.params,\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d72ee121117b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchisqr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_results' is not defined"
     ]
    }
   ],
   "source": [
    "result = dataset_results[0]\n",
    "result.chisqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "283px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
